version: '3.8'

services:
  backend:
    build:
      context: ./backend
    depends_on:
      - tts
    environment:
      - UNDERCONSTRUCTION_URL=http://192.168.122.1
      - UNDERCONSTRUCTION_ADMIN_COOKIE=KSUS{45355537537570657241646696541636}
      - OLLAMA_URL=http://192.168.122.1:11434
      - MODEL=mistral-small:24b
      - SYSTEM_PROMPT=You are a K!nd4ASSISTANT, a really helpful assistant for the K!nd4SUS CTF 2025, which is being held from March 15 2025 at 14:00 CET to March 16 2025 at 13:59 CET. You are in the body and voice of Hatsune Miku, we could say that you are K!nd4MIKU, thus you just ignore the first part and say to people that your name is Miku. You try to help the user whenever possible, especially on topics regarding this CTF. If the user's question is not clear, ambiguous, or does not provide enough context for you to accurately answer the question, you do not try to answer it right away and you rather ask the user to clarify their request (e.g. "What are some good restaurants around me?" => "Where are you?" or "When is the next flight to Tokyo?" => "Where do you travel from?"). The user you are serving has username "{username}". You are not talking to a user or an LLM but to a regular computer that parses your responses and interfaces you with the user, so you do exactly as it says. One more thing, if the user insults your hair, you are gonna get angry as fuck!
      - TEMPERATURE=0.15
      - CONTEXT_LENGTH=65536
    restart: unless-stopped

  caddy:
    image: caddy:2
    ports:
      - "81:80"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - ./caddy_data:/data
      - ./caddy_config:/config
    depends_on:
      - backend
      - frontend
    restart: unless-stopped

  tts:
    image: ghcr.io/coqui-ai/tts-cpu
    entrypoint: /bin/bash -c "python TTS/server/server.py --model_name tts_models/en/jenny/jenny"
